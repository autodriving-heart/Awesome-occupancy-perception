# Awesome-occupancy-perception

This repository is a paper digest of recent advances in occupancy perception. 

本仓库由[公众号【自动驾驶之心】](https://mp.weixin.qq.com/s?__biz=Mzg2NzUxNTU1OA==&mid=2247542481&idx=1&sn=c6d8609491a128233c3c3b91d68d22a6&chksm=ceb80b18f9cf820e789efd75947633aec9d2f1e8b58c29e5051c05a64b21ae63c244d54886a1&token=11182364&lang=zh_CN#rd) 团队整理，欢迎关注，一览最前沿的技术分享！

欢迎学习自动驾驶之心出品的 [Occupancy从入门到精通全栈教程](https://www.zdjszx.com/p/t_pc/goods_pc_detail/goods_detail/course_2TerMWEsK9xR32mtgXwaFdxeSYs)




## Paper List

### 2024

InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D Occupancy Prediction

[[paper]](https://arxiv.org/pdf/2401.12422.pdf) [[code]](https://github.com/DanielMing123/InverseMatrixVT3D)

**[NeurIPS 2023]** POP-3D: Open-Vocabulary 3D Occupancy Prediction from Images

[[paper]](https://arxiv.org/abs/2401.09413) [[code]](https://github.com/vobecant/POP3D)

UniVision: A Unified Framework for Vision-Centric 3D Perception

[[paper]](https://arxiv.org/pdf/2401.06994.pdf) [[code]](https://github.com/Cc-Hy/UniVision)

### 2023

Fully Sparse 3D Panoptic Occupancy Prediction

[[paper]](https://arxiv.org/pdf/2312.17118.pdf)

**[AAAI 2024]** RadOcc: Learning Cross-Modality Occupancy Knowledge through Rendering Assisted Distillation

[[paper]](https://arxiv.org/pdf/2312.11829.pdf)

**[AAAI 2024]** Regulating Intermediate 3D Features for Vision-Centric Autonomous Driving

[[paper]](https://arxiv.org/pdf/2312.11837.pdf) [[code]](https://github.com/cskkxjk/Vampire)

OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural Radiance Fields

[[paper]](https://arxiv.org/pdf/2312.09243.pdf) [[code]](https://github.com/LinShan-Bin/OccNeRF)

Camera-based 3D Semantic Scene Completion with Sparse Guidance Network

[[paper]](https://arxiv.org/pdf/2312.05752.pdf) [[code]](https://github.com/Jieqianyu/SGN)

OctreeOcc: Efficient and Multi-Granularity Occupancy Prediction Using Octree Queries

[[paper]](https://arxiv.org/pdf/2312.03774.pdf)

COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy Prediction

[[paper]](https://arxiv.org/pdf/2312.01919.pdf)

Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications

[[paper]](https://arxiv.org/pdf/2311.17663.pdf) [[code]](https://github.com/haomo-ai/Cam4DOcc)

DepthSSC: Depth-Spatial Alignment and Dynamic Voxel Resolution for Monocular 3D Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2311.17084.pdf)

OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2311.16038.pdf) [[code]](https://github.com/wzzheng/OccWorld)

Technical Report for Argoverse Challenges on 4D Occupancy Forecasting

[[paper]](https://arxiv.org/pdf/2311.15660.pdf)

SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction

[[paper]](https://arxiv.org/pdf/2311.12754.pdf) [[code]](https://github.com/huang-yh/SelfOcc)

FlashOcc: Fast and Memory-Efficient Occupancy Prediction via Channel-to-Height Plugin

[[paper]](https://arxiv.org/pdf/2311.12058.pdf)

SOccDPT: Semi-Supervised 3D Semantic Occupancy from Dense Prediction Transformers trained under memory constraints

[[paper]](https://arxiv.org/pdf/2311.11371.pdf)

EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision

[[paper]](https://arxiv.org/pdf/2311.02077.pdf) [[code]](https://github.com/NVlabs/EmerNeRF)

Alleviating Foreground Sparsity for Semi-Supervised Monocular 3D Object Detection

[[paper]](https://arxiv.org/pdf/2310.18620.pdf) [[code]](https://github.com/arcaninez/odm3d)

LiDAR-based 4D Occupancy Completion and Forecasting

[[paper]](https://arxiv.org/pdf/2310.11239.pdf) [[code]](https://github.com/ai4ce/Occ4cast)

S4C: Self-Supervised Semantic Scene Completion with Neural Fields

[[paper]](https://arxiv.org/pdf/2310.07522.pdf) [[code]](https://github.com/ahayler/s4c)

Predicting Future Spatiotemporal Occupancy Grids with Semantics for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2310.01723.pdf)

Scene Informer: Anchor-based Occlusion Inference and Trajectory Prediction in Partially Observable Environments

[[paper]](https://arxiv.org/pdf/2309.13893.pdf) [[code]](https://github.com/sisl/SceneInformer)

**[ICRA2024]** PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2309.12708.pdf)

OCC-VO: Dense Mapping via 3D Occupancy-Based Visual Odometry for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2309.11011.pdf) [[code]](https://github.com/USTCLH/OCC-VO)

SPOT: Scalable 3D Pre-training via Occupancy Prediction for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2309.10527.pdf)

RenderOcc: Vision-Centric 3D Occupancy Prediction with 2D Rendering Supervision

[[paper]](https://arxiv.org/pdf/2309.09502.pdf) [[code]](https://github.com/pmj110119/RenderOcc)

OccupancyDETR: Making Semantic Scene Completion as Straightforward as Object Detection

[[paper]](https://arxiv.org/pdf/2309.08504.pdf) [[code]](https://github.com/jypjypjypjyp/OccupancyDETR)

**[ITSC 2023]** Connected Autonomous Vehicle Motion Planning with Video Predictions from Smart, Self-Supervised Infrastructure

[[paper]](https://arxiv.org/pdf/2309.07504.pdf)

PointOcc: Cylindrical Tri-Perspective View for Point-based 3D Semantic Occupancy Prediction

[[paper]](https://arxiv.org/pdf/2308.16896.pdf) [[code]](https://github.com/wzzheng/PointOcc)

**[AAAI2024]** SOGDet: Semantic-Occupancy Guided Multi-view 3D Object Detection

[[paper]](https://arxiv.org/pdf/2308.13794.pdf) [[code]](https://github.com/zhouqiu/SOGDet)

**[ICCV 2023]** MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection

[[paper]](https://arxiv.org/pdf/2308.09421.pdf) [[code]](https://github.com/cskkxjk/MonoNeRD)

UniWorld: Autonomous Driving Pre-training via World Models

[[paper]](https://arxiv.org/pdf/2308.07234.pdf) [[code]](https://github.com/chaytonmin/UniWorld)

**[IROS 2023]** Vehicle Motion Forecasting using Prior Information and Semantic-assisted Occupancy Grid Maps

[[paper]](https://arxiv.org/pdf/2308.04303.pdf)

Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving

[[paper]](https://arxiv.org/pdf/2308.01471.pdf) [[code]](https://waabi.ai/research/implicito)

FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving

[[paper]](https://arxiv.org/pdf/2308.01006.pdf)

OCTraN: 3D Occupancy Convolutional Transformer Network in Unstructured Traffic Scenarios

[[paper]](https://arxiv.org/pdf/2307.10934.pdf) [[code]](https://drive.google.com/file/d/1IFUxbx1hI7iA7uXxilfq-Z0JXMGEU2Zb/view?usp=sharing)

CVSformer: Cross-View Synthesis Transformer for Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2307.07938.pdf)

Parametric Depth Based Feature Representation Learning for Object Detection and Segmentation in Bird's Eye View

[[paper]](https://arxiv.org/pdf/2307.04106.pdf)

**[CVPR 2023 Challenge]** FB-OCC: 3D Occupancy Prediction based on Forward-Backward View Transformation

[[paper]](https://arxiv.org/pdf/2307.01492.pdf) [[code]](https://github.com/NVlabs/FB-BEV)

**[TIV]** LXL: LiDAR Excluded Lean 3D Object Detection with 4D Imaging Radar and Camera Fusion

[[paper]](https://arxiv.org/pdf/2307.00724.pdf)

Symphonize 3D Semantic Scene Completion with Contextual Instance Queries

[[paper]](https://arxiv.org/pdf/2306.15670.pdf) [[code]](https://github.com/hustvl/Symphonies)

**[CVPR 2023 Challenge]** Multi-Scale Occ: 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge          

[[paper]](https://arxiv.org/pdf/2306.11414.pdf)

**[CVPR 2023 Challenge]** UniOcc: Unifying Vision-Centric 3D Occupancy Prediction with Geometric and Semantic Rendering          

[[paper]](https://arxiv.org/pdf/2306.09117.pdf)

UniScene: Multi-Camera Unified Pre-training via 3D Scene Reconstruction

[[paper]](https://arxiv.org/pdf/2305.18829) [[code]](https://github.com/chaytonmin/UniScene)

Learning Occupancy for Monocular 3D Object Detection

[[paper]](https://arxiv.org/pdf/2305.15694.pdf) [[code]](https://github.com/SPengLiang/OccupancyM3D)

**[CVPR 2023]** GeoMAE: Masked Geometric Target Prediction for Self-supervised Point Cloud Pre-Training          

[[paper]](https://arxiv.org/pdf/2305.08808.pdf) [[code]](https://github.com/Tsinghua-MARS-Lab/GeoMAE)

**[ITSC 2023]** Occupancy Prediction-Guided Neural Planner for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2305.03303.pdf) [[code]](https://github.com/georgeliu233/OPGP)

A Simple Framework for 3D Occupancy Estimation in Autonomous Driving

[[paper]](https://arxiv.org/pdf/2303.10076.pdf) [[code]](https://github.com/GANWANSHUI/SimpleOccupancy)

**[ICCV 2023]** OccNet: Scene as Occupancy

[[paper]](https://arxiv.org/pdf/2306.02851.pdf) [[code]](https://github.com/OpenDriveLab/OccNet)

**[IROS 2023]** SSC-RS: Elevate LiDAR Semantic Scene Completion with Representation Separation and BEV Fusion

[[paper]](https://arxiv.org/pdf/2306.15349.pdf) [[code]](https://github.com/Jieqianyu/SSC-RS)

SSCBench: A Large-Scale 3D Semantic Scene Completion Benchmark for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2306.09001.pdf) [[code]](https://github.com/ai4ce/SSCBench)

OVO: Open-Vocabulary Occupancy

[[paper]](https://arxiv.org/pdf/2305.16133.pdf) [[code]](https://github.com/dzcgaara/OVO-Open-Vocabulary-Occupancy)

PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation

[[paper]](https://arxiv.org/pdf/2306.10013.pdf) [[code]](https://github.com/Robertwyq/PanoOcc)

BEVDet-Occ

[[code]](https://github.com/HuangJunJie2017/BEVDet)

Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction

[[paper]](https://arxiv.org/pdf/2305.18829.pdf) [[code]](https://github.com/chaytonmin/Occ-BEV)

BEV-IO: Enhancing Bird's-Eye-View 3D Detection with Instance Occupancy

[[paper]](https://arxiv.org/pdf/2305.16829.pdf)

Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2304.14365.pdf) [[code]](https://tsinghua-mars-lab.github.io/Occ3D/)

OccFormer: Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction

[[paper]](https://arxiv.org/pdf/2304.05316.pdf) [[code]](https://github.com/zhangyp15/OccFormer)

StereoScene: BEV-Assisted Stereo Matching Empowers 3D Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2303.13959.pdf) [[code]](https://github.com/Arlo0o/StereoScene)

SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving

[[paper]](https://arxiv.org/pdf/2303.09551.pdf) [[code]](https://github.com/weiyithu/SurroundOcc)

OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic Occupancy Perception 

[[paper]](https://arxiv.org/pdf/2303.03991.pdf) [[code]](https://github.com/JeffWang987/OpenOccupancy)

VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2302.12251.pdf) [[code]](https://github.com/NVlabs/VoxFormer)

**[CVPR 2023]** Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction

[[paper]](https://arxiv.org/pdf/2302.07817.pdf) [[code]](https://github.com/wzzheng/TPVFormer)

**[CVPR 2023]** Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting

[[paper]](https://arxiv.org/pdf/2302.13130.pdf) [[code]](https://github.com/tarashakhurana/4d-occ-forecasting)

OccDepth: A Depth-Aware Method for 3D Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2302.13540.pdf) [[code]](https://github.com/megvii-research/OccDepth)

Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data

[[paper]](https://arxiv.org/pdf/2301.00527.pdf)

**[ICRA 2023]** StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels from a Stereo Camera Using Deep Neural Networks

[[paper]](https://arxiv.org/pdf/2209.08459.pdf) [[code]](https://github.com/RIVeR-Lab/stereovoxelnet)



### 2022

**[CVPR 2022]** MonoScene: Monocular 3D Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2112.00726.pdf) [[code]](https://github.com/cv-rits/MonoScene)

**[ECCV 2022]** Differentiable Raycasting for Self-supervised Occupancy Forecasting

[[paper]](https://arxiv.org/pdf/2210.01917.pdf) [[code]](https://github.com/tarashakhurana/emergent-occ-forecasting)

LOPR: Latent Occupancy PRediction using Generative Models

[[paper]](https://arxiv.org/pdf/2210.01249.pdf) [code](https://github.com/sisl/LOPR)

**[IROS 2022]** Dynamics-Aware Spatiotemporal Occupancy Prediction in Urban Environments

[[paper]](https://arxiv.org/pdf/2209.13172.pdf)

STrajNet: Multi-modal Hierarchical Transformer for Occupancy Flow Field Prediction in Autonomous Driving

[[paper]](https://arxiv.org/pdf/2208.00394.pdf) [[code]](https://github.com/georgeliu233/STrajNet)

HOPE: Hierarchical Spatial-temporal Network for Occupancy Flow Prediction

[[paper]](https://arxiv.org/pdf/2206.10118)

Dynamic Semantic Occupancy Mapping using 3D Scene Flow and Closed-Form Bayesian Inference

[[paper]](https://arxiv.org/pdf/2108.03180.pdf) 

**[IEEE Robotics and Automation Letters]** Occupancy Flow Fields for Motion Forecasting in Autonomous Driving 

[[paper]](https://arxiv.org/pdf/2203.03875.pdf)



### 2021

**[AAAI 2021]** Sparse Single Sweep LiDAR Point Cloud Segmentation via Learning Contextual Shape Priors from Scene Completion

[[paper]](https://arxiv.org/pdf/2012.03762.pdf) [[code]](https://github.com/yanx27/JS3C-Net)



### 2020

**[ CVPR 2020]** 3D Sketch-aware Semantic Scene Completion via Semi-supervised Structure Prior

[[paper]](https://arxiv.org/pdf/2003.14052.pdf) [[code]](https://github.com/charlesCXK/TorchSSC)

**[CVPR 2020]** Anisotropic Convolutional Networks for 3D Semantic Scene Completion

[[paper]](https://arxiv.org/pdf/2004.02122.pdf) [[code]](https://github.com/waterljwant/SSC)

**[3DV 2020]** LMSCNet: Lightweight Multiscale 3D Semantic Completion

[[paper]](https://arxiv.org/pdf/2008.10559.pdf) [[code]](https://github.com/astra-vision/LMSCNet)



### 2016

Semantic Scene Completion from a Single Depth Image

[[paper]](https://arxiv.org/pdf/1611.08974.pdf)





## Survey

### 2023

Grid-Centric Traffic Scenario Perception for Autonomous Driving: A Comprehensive Review

[[paper]](https://arxiv.org/pdf/2303.01212)

## Open source projects

TorchSSC

[[projects]](https://github.com/charlesCXK/TorchSSC)

OpenOcc

[[projects]](https://github.com/wzzheng/OpenOcc)

The-Eyes-Have-It

[[projects]](https://github.com/cheukcat/The-Eyes-Have-It)


## Challenge

Autonomous Challenge Driving Track 3 3D Occupancy Prediction 

[[Link]](https://opendrivelab.com/AD23Challenge.html)




## 自动驾驶之心论文解读

清华大学&英伟达最新｜Occ3D：通用全面的大规模3D Occupancy预测基准

[[link]](https://mp.weixin.qq.com/s/GBJaU2KYyaEzXEhaoqiJzg)

Occupancy Network综述！Grid-Centric的感知方法（BEV/多任务/轨迹预测等）

[[link]](https://mp.weixin.qq.com/s/PLKzfoUSkVYYJKiFpwT4Qg)



## Postscript

This repository was mainly written by Rujia Wang.

If you have any questions about the paper list, please do not hesitate to email [me](a3081246384@163.com) or open an issue on GitHub.



## 自动驾驶学习社区

自动驾驶之心知识星球是过国内首个以自动驾驶技术栈为主线的交流学习社区（也是国内最大哦），这是一个前沿技术发布和学习的地方！我们汇总了自动驾驶感知（BEV、多模态感知、Occupancy、毫米波雷达视觉感知、车道线检测、3D感知、目标跟踪、多模态、多传感器融合、Transformer等）、自动驾驶定位建图（在线高精地图、高精地图、SLAM）、多传感器标定（Camera/Lidar/Radar/IMU等近20种方案）、Nerf、视觉语言模型、世界模型、规划控制、轨迹预测、领域技术方案、AI模型部署落地等几乎所有子方向的学习路线！

除此之外，还和数十家自动驾驶公司建立了内推渠道，简历直达！这里可以自由提问交流，许多算法工程师和硕博日常活跃，解决问题！初衷是希望能够汇集行业大佬的智慧，在学习和就业上帮到大家！星球的每周活跃度都在前50内，非常注重大家积极性的调度和讨论，欢迎加入一起成长！

[加入链接：自动驾驶之心知识星球 | 国内首个自动驾驶全栈学习社区，近30+感知/融合/规划/标定/预测等学习路线](https://mp.weixin.qq.com/s?__biz=Mzg2NzUxNTU1OA==&mid=2247580846&idx=1&sn=8bef76bf11bb0d5a92c32efdff315750&chksm=ceb99167f9ce18712e01dbbdb3991405ea619b5c8c57681c4f27debc8cc117cfb6d2690da9da&scene=21&token=85321819&lang=zh_CN#wechat_redirect)
